"""Tests for the BatchProcessor class."""

import os
import json
import tempfile
import unittest
from unittest.mock import patch, MagicMock
from pathlib import Path

from aiflux.processors.batch import BatchProcessor
from aiflux.core.config import ModelConfig, ModelParameters
from aiflux.io.base import OutputResult

class TestBatchProcessor(unittest.TestCase):
    """Test suite for the BatchProcessor class."""
    
    def setUp(self):
        """Set up test environment."""
        self.temp_dir = tempfile.TemporaryDirectory()
        self.test_dir = Path(self.temp_dir.name)
        
        # Create a test model config
        self.model_params = ModelParameters(
            temperature=0.7,
            max_tokens=500,
            top_p=0.9,
            top_k=40,
            stop_sequences=None
        )
        
        self.model_config = ModelConfig(
            name="test-model",
            type="test",
            size="7b",
            parameters=self.model_params,
            path=None,
            description="Test model",
            capabilities=["text"]
        )
        
        # Create a test JSONL file
        self.jsonl_path = self.test_dir / "test.jsonl"
        
        # Sample JSONL entries
        self.entries = [
            {
                "custom_id": "test-1",
                "method": "POST",
                "url": "/v1/chat/completions",
                "body": {
                    "model": "test-model",
                    "messages": [
                        {"role": "system", "content": "You are a helpful assistant."},
                        {"role": "user", "content": "Hello, world!"}
                    ],
                    "temperature": 0.7,
                    "max_tokens": 500
                }
            },
            {
                "custom_id": "test-2",
                "method": "POST",
                "url": "/v1/chat/completions",
                "body": {
                    "model": "test-model",
                    "messages": [
                        {"role": "user", "content": "How are you?"}
                    ],
                    "temperature": 0.5,
                    "max_tokens": 100
                }
            }
        ]
        
        with open(self.jsonl_path, "w") as f:
            for entry in self.entries:
                f.write(json.dumps(entry) + "\n")
        
        # Output path
        self.output_path = self.test_dir / "output.json"
    
    def tearDown(self):
        """Clean up test environment."""
        self.temp_dir.cleanup()
    
    @patch('aiflux.processors.batch.LLMClient')
    def test_batch_processor_initialization(self, mock_client_class):
        """Test BatchProcessor initialization."""
        processor = BatchProcessor(model_config=self.model_config)
        
        # Check properties
        self.assertEqual(processor.model_config, self.model_config)
        self.assertEqual(processor.batch_size, 4)  # Default value
        self.assertEqual(processor.save_frequency, 50)  # Default value
        self.assertIsNone(processor.client)  # Client initialized in setup
    
    @patch('aiflux.processors.batch.LLMClient')
    def test_batch_processor_setup(self, mock_client_class):
        """Test BatchProcessor setup."""
        # Mock client instance
        mock_client = MagicMock()
        mock_client_class.return_value = mock_client
        
        processor = BatchProcessor(model_config=self.model_config)
        processor.setup()
        
        # Check that client was created
        self.assertIsNotNone(processor.client)
        mock_client_class.assert_called_once()
        
        # Check that warmup was called
        mock_client.generate.assert_called_once()
    
    @patch('aiflux.processors.batch.LLMClient')
    def test_process_batch(self, mock_client_class):
        """Test processing a batch of items."""
        # Mock client instance
        mock_client = MagicMock()
        mock_client.generate.return_value = "This is a test response."
        mock_client_class.return_value = mock_client
        
        processor = BatchProcessor(model_config=self.model_config)
        processor.setup()
        
        # Process batch
        results = processor.process_batch(self.entries)
        
        # Check that we have two results
        self.assertEqual(len(results), 2)
        
        # Check first result
        self.assertEqual(results[0].input, self.entries[0])
        self.assertIsNotNone(results[0].output)
        self.assertIn("This is a test response.", str(results[0].output))
        
        # Check that generate was called with correct parameters
        mock_client.generate.assert_any_call(
            model="test-model",
            messages=self.entries[0]["body"]["messages"],
            temperature=0.7,
            max_tokens=500,
            top_p=0.9,
            stop=None
        )
    
    @patch('aiflux.processors.batch.LLMClient')
    def test_run_with_jsonl(self, mock_client_class):
        """Test running the processor with a JSONL file."""
        # Mock client instance
        mock_client = MagicMock()
        mock_client.generate.return_value = "This is a test response."
        mock_client_class.return_value = mock_client
        
        processor = BatchProcessor(model_config=self.model_config)
        
        # Run processor
        results = processor.run(self.jsonl_path, self.output_path)
        
        # Check results
        self.assertEqual(len(results), 2)
        
        # Check that output file was created
        self.assertTrue(os.path.exists(self.output_path))
        
        # Read output file
        with open(self.output_path, "r") as f:
            output_data = json.load(f)
        
        # Check output data
        self.assertEqual(len(output_data), 2)
        self.assertEqual(output_data[0]["input"]["custom_id"], "test-1")
        self.assertEqual(output_data[1]["input"]["custom_id"], "test-2")
    
    @patch('aiflux.processors.batch.LLMClient')
    def test_error_handling(self, mock_client_class):
        """Test error handling in processing."""
        # Mock client instance to raise an exception
        mock_client = MagicMock()
        mock_client.generate.side_effect = Exception("Test error")
        mock_client_class.return_value = mock_client
        
        processor = BatchProcessor(model_config=self.model_config)
        processor.setup()
        
        # Process batch
        results = processor.process_batch(self.entries)
        
        # Check that we have two results with errors
        self.assertEqual(len(results), 2)
        self.assertIsNone(results[0].output)
        self.assertEqual(results[0].error, "Test error")
        self.assertTrue(results[0].metadata.get("error"))
    
    @patch('aiflux.processors.batch.LLMClient')
    def test_completion_endpoint(self, mock_client_class):
        """Test handling the completions endpoint."""
        # Create a test JSONL with completions endpoint
        completions_jsonl = self.test_dir / "completions.jsonl"
        completion_entry = {
            "custom_id": "completion-1",
            "method": "POST",
            "url": "/v1/completions",
            "body": {
                "model": "test-model",
                "prompt": "Complete this sentence: The sky is",
                "temperature": 0.7,
                "max_tokens": 500
            }
        }
        
        with open(completions_jsonl, "w") as f:
            f.write(json.dumps(completion_entry) + "\n")
        
        # Mock client instance
        mock_client = MagicMock()
        mock_client.generate.return_value = "blue"
        mock_client_class.return_value = mock_client
        
        processor = BatchProcessor(model_config=self.model_config)
        
        # Run processor
        results = processor.run(completions_jsonl, self.output_path)
        
        # Check that generate was called with expected parameters
        mock_client.generate.assert_called_with(
            model="test-model",
            messages=[{"role": "user", "content": "Complete this sentence: The sky is"}],
            temperature=0.7,
            max_tokens=500,
            top_p=0.9,
            stop=None
        )
        
        # Check output format
        self.assertEqual(len(results), 1)
        output = results[0].output
        self.assertEqual(output["object"], "text_completion")
        self.assertEqual(output["choices"][0]["text"], "blue")

if __name__ == "__main__":
    unittest.main() 